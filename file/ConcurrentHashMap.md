## 1.JDK1.7 与 JDK1.8 中ConcurrentHashMap 的区别?

#### 1.1.从数据结构上：

1> JDK1.7 ConCurrentHashMap使用Segment数组 + 键值对主体HashEntry，一个Segment中又包含一个HashEntry数组，每个HashEntry是一个链表结构的元素；
2> JDK1.8 ConCurrentHashMap改用数组、链表、红黑树相结合的数据结构。

#### 1.2.从线程安全机制上：

1> JDK1.7 采用 Segment 的分段锁机制实现线程安全，其中 Segment 继承自 ReentrantLock ；
2> JDK1.8 采用CAS+synchronized 保证线程安全；对数组 / 链表 / 红黑树节点数据修改时使用CAS，操作每个数组元素中链表 / 红黑树时加Synchronized锁。

#### 1.3.从锁的粒度上：

1> JDK1.7 是对需要进行数据操作的 Segment 加锁，也就是对一段HashEntry数组加锁；
2> JDK1.8 则是对每个数组元素Node加锁；相较于JDK1.7而言锁更加细粒度，并发度更高。

#### 1.4.从查询时间复杂度上：

1> JDK1.7当发生Hash冲突时一直往链表尾部追加，遍历链表的时间复杂度为O(n)；
2> JDK1.8当链表节点数量大于 8（且数据总量大于等于 64）时，会将链表转化为红黑树进行存储；此时遍历红黑树的时间复杂度为O(logn)。



## 2.ConcurrentHashMap中变量使用final和volatile修饰的作用？

final变量修饰属性变量时，表示它为一个常量，一经初始化，便不可进行修改，它能确保变量的初始化安全性，初始化安全性让不可变对象不需要同步就可以被自由的访问和共享

volatile可以保证对一个变量进行写操作后，把当前线程中工作内存的变量同步到主内存中去，也可以保证对一个变量的读操作之前，从主内存中获取变量到当前线程工作内存中

volatile关键字保证某个变量内存的改变对其他线程即时可见；再配合CAS可以实现无锁并发操作，比如 Node的元素val和指针next使用volatile修饰，因此在多线程环境下线程A修改Node节点的val或者新增节点对线程B是可见的。以及控制扩容的sizeCtl、存放数据的table、扩容用的nextTable,  树节点TreeNode中没加volatile关键字，因为操作树节点时，一定加了synchronized关键字,操作树节点肯定是操作单个数组元素，ConcurrentHashMap操作数组元素时都会synchronized锁住该数组元素

get()方法可以无锁，是由于Node的元素val和指针next都是volatile修饰的，在多线程环境下线程A修改节点的val或者新增节点对线程B是可见的

## 3.在多线程场景下，如何保证插入数据线程安全？（put操作）

首先，校验key和value不能为null，否者会抛出空指针异常。检验通过之后会通过使用异或和与操作的扰动函数计算key的hash值。

接下来总体流程分为两部分

第一部分对table数组在死循环中进行节点的插入或者替换操作

第二部分调用addCount方法将ConcurrentHashMap存储的节点总数+1

第一部分中有四种情况,

1.如果table没有初始化，就调用initTable方法进行table的初始化，具体操作为在一个while死循环(条件为数组为空)中，首先判断sizectl是否<0（代表正在初始化或者扩容）,如果是就调用Thread.yield()尽量让出cpu让别的线程进行初始化操作,否则就cas把sizectl设置为-1，成功了，就进行初始化逻辑，如果sizectl>0(这里sizectl已经为-1，不过有一个变量暂存了他之前的值，这里是判断那个变量)，代表存储的是容量，那么就初始化sizectl大小的数组，如果<0,就使用默认值16，作为数组的大小，并且设置阈值为n - (n >>> 2)实际就是0.75倍的容量,最后在finally块中会把sizectl设置为这个阈值.

2.如果当前key得到的hash和数组长度-1进行与操作（实际就是取余操作）得到的一个数组下标再从table中找到的那个元素为null，说明当前没有发生hash冲突，直接cas将当前数组位置的元素设置为我们要插入的节点.

3.如果当前索引所在元素不为null，并且发现它的hash值为MOVED（-1）说明当前table正在扩容，这时候就调用helpTransfer方法帮助扩容.

4.如果发现元素的hash值为其他情况,先synchronized锁住该数组元素，如果是普通链表节点，遍历链表，如果发现重复元素，就更具onlyifAbsent变量判断是否替换，默认是替换，如果找到最后都没有发现重复节点，就将当前节点插入到链表尾部。 如果是红黑树节点，调用红黑树的putTreeVal方法，如果返回null说明是新建节点，如果不为null，则会返回重复节点，再根据链表一样的操作是否替换。

如果链表长度大于了8，则会调用treeifyBin方法进行树化，不过也不一定会树化，如果table容量<64，则会进行扩容，只有table>64才会进行树化,因为它觉得，当前有这么激烈的hash冲突是由于数组的长度太小而导致的，所以对数组进行扩容。



第二部分addCount有两个参数，第一个固定为1表示节点总数增加1，第二个参数binCount

addCount又分为计数部分 和扩容部分

binCount取值：//执行的是else if ((f = tabAt(tab, i = (n - 1) & hash)) == null)这段逻辑，此时binCount为0
							//或者是红黑树put流程找到了新建节点，此时binCount等于2
							//或者当前为链表插入节点，binCount为链表的长度(不包括这个新建的节点)

计数部分：

ConcurrentHashMap中的节点计数采用LongAdder的分段cas思想，一个baseCount变量，一个counterCells数组，最后计数是baseCount+数组中的每一个元素。

首先判断counterCells是否为null，为null就cas设置baseCount为baseCount+第一个参数的值，cas成功的话计数部分就完成了，

失败的话走fullAddCount方法在里面进行增加计数的操作（uncontended = true）。 如果counterCells不为null，用ThreadLocalRandom探针机制随机找到数组中的一个索引，如果为null，调用fullAddCount方法在里面进行增加计数的操作（uncontended = true），如果不为null，cas设置这个索引所在元素的值进行增加操作，成功就返回(如果不需要扩容),失败的话就调用fullAddCount方法在里面进行增加计数的操作（uncontended = false）。

上述操作如果调用了fullAddCount方法都会直接返回，不会管这个addCount方法里面的扩容部分。

如果第二个参数<=1，说明不需要扩容，直接返回，否则计算出当前size，走扩容部分流程.



扩容部分:

首先判断第二个参数>=0,才走扩容的逻辑,如果当前的size>=阈值，并且table的容量小于最大值,走扩容逻辑,根据当前容量获取一个唯一对应的标签值，如果当前正在扩容将sizectl后16位+1，然后调用transfer方法，否则将sizectl后16位+2，然后调用transfer方法.



## 4.哪些情况下，会触发扩容⾏为？

1.如果在新增节点之后，链表的长度达到了阈值8，会调用`treeifyBin(tab, i)`方法将链表转为红黑树；不过在`treeifyBin(tab, i)`方法中会先对数组长度进行判断，如果数组长度 小于 64，则会调用`tryPresize(n << 1)`方法对数组进行扩容两倍.

2.新增节点之后，会调用`addCount()`方法将元素个数+1，并检查是否需要进行扩容，当数组元素个数达到扩容阈值`sizeCtl`时，会触发`transfer()`方法，对数组进行两倍扩容

3.在put操作时，如果发现当前索引所在元素hash值为MOVED，会调用 helpTransfer(tab, f)帮忙扩容，这也可能会触发扩容行为。



## 5.在多线程场景下，它时如何扩容的？

第一个进入扩容的线程会调用transfer(tab,null)方法进行扩容，后面来帮助扩容的线程调用transfer(tab,newTab)方法进行扩容

transfer方法总体可以分为两部分  **移动遍历指针部分**和**处理当前遍历哈希桶部分**

**移动遍历指针部分**：首先根据当前数组长度n，通过n/8/当前可用cpu核心数，得到每个线程遍历的步长，如果算出来的结果<16的话，就会取默认值16，如果当前nextTable为null，说明是第一个进来扩容的线程，创建一个旧数组两倍长度的新数组赋值给nextTable，并且把transferIndex（代表下一次领取的扩容任务的索引上界）赋值为旧数组的长度，把nextTable包装成为一个ForwardingNode节点，这样当其他线程对map进行操作时，会发现当前状态为MOVED，就会帮忙扩容。这个遍历过程是从旧数组的最后一个元素开始往前遍历，每次遍历计算出来的步长数量，不同的线程进来就会分别领取数组中某一段还没被领取的步长的那几个元素，进行扩容的操作(因为是并发的情况，领取到哪一段都是不确定的).



**处理当前遍历哈希桶部分**: 通过上一步骤，当前线程已经拿到了自己要处理的那几个元素，并且会从后往前遍历他们进行扩容。首先判断当前是否已经处理完了自己的所有元素，如果是，就要归还许可了，会将sizeCtl后16位-1，如果当前不是最后一个线程来归还，直接返回，如果是，那么还要再对旧数组进行一次全部遍历收尾工作。当前遍历哈希桶为null，那好办，设置为ForwardingNode即可。如果当前遍历哈希桶的hash值为MOVED，说明当前元素已经完成了迁移操作，下面开始走迁移操作的流程。

数组迁移可能分离到两个地方，一个是原地不动 i，一个是i + 旧容量，称它们为低桶和高桶，如果当前元素上的节点新的起作用的那一位为1，那么它就会到高桶上面去，如果为0，那么到低桶去，如果当前是红黑树节点，如果链表分离了，那么分离后还要进行树化操作（并且如果它的长度<8，那么还要进行untree，还原成链表结构），因为这样就破坏了红黑树的结构，如果没有分离，因为它是尾插法，还是按照原来的顺序没有发生改变，所以就不需要树化。



## 6.为什么计算总参与扩容操作线程数的时候，是从2开始的？为什么不从1开始计算？

这个得说一下sizeCtl这个变量它不同的值对应不同的场景，

1，当数组没有初始化时，它存的是数组的容量。

2，当数组已经初始化，且没有其他操作，存放的是阈值。

3，当数组正在初始化时，它的值为-1。

4，当数组正在扩容时，它一定会是一个复数，因为用位运算保证了它第一位为1。

所以如果当我们第一次扩容时+1，而不是+2，那么它的值为-1就和第三种情况冲突了，所以这里是必须要+2。



## 7.扩容期间在未迁移到的hash桶插入数据会发生什么？

不会出现问题，未迁移的话，会直接插入，不影响，

如果正在迁移，就会帮助扩容，扩容完成后，再加synchronized锁执行插入操作。



## 8.ConcurrentHashMap是如何计算拥有的kv总量？

ConcurrentHashMap设置了两个变量baseCount和counterCells，借用了LongAdder的分段cas思想，可以并发的修改map的容量，计算容量是baseCount+counterCells中每一个元素得到总容量



## 9.CounterCell数组何时会扩容？扩容的原因是什么？

当探针取余下标不为null，并且cas修改该下标元素失败，并且countercell数组没有发生改变，且当前数组长度小于当前cpu核心数，并且上述逻辑已经走了两遍还是和上述条件情况相同，那么此时就需要扩容。

原因：当前数组长度太小，导致并发情况下，hash冲突激烈，多个线程同时竞争同一个数组下标元素，使得整体效率下降，扩容就可以缓解这个问题，提高效率。



## 10.ConcurrentHashMap的get方法是否要加锁，为什么？

不需要，map中的共享变量都用volatile修饰，能保证其可见性，不加锁可以提高效率，由于不加锁，map的迭代器遍历是弱一致性，提高效率。



## 11.正在迁移的hash桶遇到 get 操作会发生什么？

get操作的线程会转发到新数组上去获取值。



## 12.ConcurrentHashMap迭代器是强一致性还是弱一致性？HashMap呢？

ConcurrentHashMap是弱一致性，hashmap是强一致性。

ConcurrentHashMap在进行迭代器遍历时如果数组或数组元素发生改变，它不会做出响应，会继续在旧数组上遍历，这就是弱一致性，牺牲一点准确度来换取更高效的性能。

HashMapforEach进行遍历，但是如果发现当前modCount（每当增加或者删除操作完成这个变量就会+1）和之前暂存的这个变量不一样，那么说明在遍历过程中数组发生了变化，这时候会直接抛出ConcurrentModificationException()异常，这就是HashMap强一致性的表现。
